{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/listakurniawati/Mathematical-Modelling-for-Chronic-Kidney-Disease-Detection-using-Multi-layer-Perceptron/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmbgAxukyPaW"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from matplotlib.pyplot import figure\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u89R3u_6rVc"
      },
      "source": [
        "# **Pemisahan Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3E65QEB0jvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "55d061a3-5496-454f-87db-91fe6f73a16e"
      },
      "source": [
        "#persiapan data\n",
        "dt = pd.read_csv('https://raw.githubusercontent.com/Syamsyuriani/CKD/main/DatasetPGK(Processed).csv')\n",
        " \n",
        "X = dt.drop(columns=['age', 'su', 'pc', 'pcc', 'ba', 'sod', 'pot', 'appet', 'pe', 'classification'])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>al</th>\n",
              "      <th>bgr</th>\n",
              "      <th>bu</th>\n",
              "      <th>sc</th>\n",
              "      <th>hemo</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>ane</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>80</td>\n",
              "      <td>1.020</td>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>15.4</td>\n",
              "      <td>44.0</td>\n",
              "      <td>7800</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>1.020</td>\n",
              "      <td>4</td>\n",
              "      <td>122</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>11.3</td>\n",
              "      <td>38.0</td>\n",
              "      <td>6000</td>\n",
              "      <td>4.232106</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>80</td>\n",
              "      <td>1.010</td>\n",
              "      <td>2</td>\n",
              "      <td>423</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>31.0</td>\n",
              "      <td>7500</td>\n",
              "      <td>3.773686</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>1.005</td>\n",
              "      <td>4</td>\n",
              "      <td>117</td>\n",
              "      <td>56.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>11.2</td>\n",
              "      <td>32.0</td>\n",
              "      <td>6700</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80</td>\n",
              "      <td>1.010</td>\n",
              "      <td>2</td>\n",
              "      <td>106</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>11.6</td>\n",
              "      <td>35.0</td>\n",
              "      <td>7300</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>80</td>\n",
              "      <td>1.020</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>15.7</td>\n",
              "      <td>47.0</td>\n",
              "      <td>6700</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>70</td>\n",
              "      <td>1.025</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>54.0</td>\n",
              "      <td>7800</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>80</td>\n",
              "      <td>1.020</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>15.8</td>\n",
              "      <td>49.0</td>\n",
              "      <td>6600</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>60</td>\n",
              "      <td>1.025</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.2</td>\n",
              "      <td>51.0</td>\n",
              "      <td>7200</td>\n",
              "      <td>5.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>80</td>\n",
              "      <td>1.025</td>\n",
              "      <td>0</td>\n",
              "      <td>131</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>15.8</td>\n",
              "      <td>53.0</td>\n",
              "      <td>6800</td>\n",
              "      <td>6.100000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>351 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     bp     sg  al  bgr    bu   sc  ...    wc        rc  htn  dm  cad  ane\n",
              "0    80  1.020   1  121  36.0  1.2  ...  7800  5.200000    1   1    0    0\n",
              "1    50  1.020   4  122  18.0  0.8  ...  6000  4.232106    0   0    0    0\n",
              "2    80  1.010   2  423  53.0  1.8  ...  7500  3.773686    0   1    0    1\n",
              "3    70  1.005   4  117  56.0  3.8  ...  6700  3.900000    1   0    0    1\n",
              "4    80  1.010   2  106  26.0  1.4  ...  7300  4.600000    0   0    0    0\n",
              "..   ..    ...  ..  ...   ...  ...  ...   ...       ...  ...  ..  ...  ...\n",
              "346  80  1.020   0  140  49.0  0.5  ...  6700  4.900000    0   0    0    0\n",
              "347  70  1.025   0   75  31.0  1.2  ...  7800  6.200000    0   0    0    0\n",
              "348  80  1.020   0  100  26.0  0.6  ...  6600  5.400000    0   0    0    0\n",
              "349  60  1.025   0  114  50.0  1.0  ...  7200  5.900000    0   0    0    0\n",
              "350  80  1.025   0  131  18.0  1.1  ...  6800  6.100000    0   0    0    0\n",
              "\n",
              "[351 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opT3-np4k0HE"
      },
      "source": [
        "#pisah data numerik\n",
        "var_kategorik = ['al', 'htn', 'dm', 'cad', 'ane']\n",
        "X_numerik = X.drop(columns=var_kategorik)\n",
        "X_kategorik = X[var_kategorik]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PArue3hAbFnu"
      },
      "source": [
        "#Standarisasi yang numerik\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_numerik)\n",
        "X_numerik = scaler.transform(X_numerik)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5HP002ymJVD"
      },
      "source": [
        "#gabung X_numerik & X_kategorik\n",
        "X_numerik = pd.DataFrame(X_numerik)\n",
        "X = pd.concat([X_numerik, X_kategorik], axis=1)\n",
        "X.rename(\n",
        "    columns=({ 0: 'bp', 1: 'sg', 2: 'bgr', 3: 'bu', 4: 'sc', 5: 'hemo', 6: 'pcv', 7: 'wc', 8: 'rc'}), \n",
        "    inplace=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "4dDmg9jfnS8k",
        "outputId": "1e322a0e-3115-4dde-823e-83da5279694b"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>bgr</th>\n",
              "      <th>bu</th>\n",
              "      <th>sc</th>\n",
              "      <th>hemo</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>al</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>ane</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.301532</td>\n",
              "      <td>0.448300</td>\n",
              "      <td>-0.341271</td>\n",
              "      <td>-0.378493</td>\n",
              "      <td>-0.385674</td>\n",
              "      <td>1.000587</td>\n",
              "      <td>0.606227</td>\n",
              "      <td>0.266754</td>\n",
              "      <td>0.629524</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.966422</td>\n",
              "      <td>0.448300</td>\n",
              "      <td>-0.328218</td>\n",
              "      <td>-0.752422</td>\n",
              "      <td>-0.498390</td>\n",
              "      <td>-0.551412</td>\n",
              "      <td>-0.126860</td>\n",
              "      <td>-0.145825</td>\n",
              "      <td>-0.450583</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.301532</td>\n",
              "      <td>-1.307875</td>\n",
              "      <td>3.600691</td>\n",
              "      <td>-0.025337</td>\n",
              "      <td>-0.216601</td>\n",
              "      <td>-1.194924</td>\n",
              "      <td>-0.982128</td>\n",
              "      <td>0.197991</td>\n",
              "      <td>-0.962149</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.454452</td>\n",
              "      <td>-2.185962</td>\n",
              "      <td>-0.393482</td>\n",
              "      <td>0.036985</td>\n",
              "      <td>0.346979</td>\n",
              "      <td>-0.589266</td>\n",
              "      <td>-0.859947</td>\n",
              "      <td>0.014622</td>\n",
              "      <td>-0.821191</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.301532</td>\n",
              "      <td>-1.307875</td>\n",
              "      <td>-0.537064</td>\n",
              "      <td>-0.586231</td>\n",
              "      <td>-0.329317</td>\n",
              "      <td>-0.437851</td>\n",
              "      <td>-0.493404</td>\n",
              "      <td>0.152149</td>\n",
              "      <td>-0.040037</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>0.301532</td>\n",
              "      <td>0.448300</td>\n",
              "      <td>-0.093267</td>\n",
              "      <td>-0.108432</td>\n",
              "      <td>-0.582927</td>\n",
              "      <td>1.114148</td>\n",
              "      <td>0.972770</td>\n",
              "      <td>0.014622</td>\n",
              "      <td>0.294744</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>-0.454452</td>\n",
              "      <td>1.326387</td>\n",
              "      <td>-0.941702</td>\n",
              "      <td>-0.482362</td>\n",
              "      <td>-0.385674</td>\n",
              "      <td>1.416977</td>\n",
              "      <td>1.828038</td>\n",
              "      <td>0.266754</td>\n",
              "      <td>1.745459</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>0.301532</td>\n",
              "      <td>0.448300</td>\n",
              "      <td>-0.615381</td>\n",
              "      <td>-0.586231</td>\n",
              "      <td>-0.554748</td>\n",
              "      <td>1.152002</td>\n",
              "      <td>1.217132</td>\n",
              "      <td>-0.008299</td>\n",
              "      <td>0.852711</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>-1.210437</td>\n",
              "      <td>1.326387</td>\n",
              "      <td>-0.432641</td>\n",
              "      <td>-0.087659</td>\n",
              "      <td>-0.442032</td>\n",
              "      <td>0.546343</td>\n",
              "      <td>1.461495</td>\n",
              "      <td>0.129228</td>\n",
              "      <td>1.410678</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>0.301532</td>\n",
              "      <td>1.326387</td>\n",
              "      <td>-0.210742</td>\n",
              "      <td>-0.752422</td>\n",
              "      <td>-0.413853</td>\n",
              "      <td>1.152002</td>\n",
              "      <td>1.705857</td>\n",
              "      <td>0.037544</td>\n",
              "      <td>1.633865</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>351 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           bp        sg       bgr        bu        sc  ...  al  htn  dm  cad  ane\n",
              "0    0.301532  0.448300 -0.341271 -0.378493 -0.385674  ...   1    1   1    0    0\n",
              "1   -1.966422  0.448300 -0.328218 -0.752422 -0.498390  ...   4    0   0    0    0\n",
              "2    0.301532 -1.307875  3.600691 -0.025337 -0.216601  ...   2    0   1    0    1\n",
              "3   -0.454452 -2.185962 -0.393482  0.036985  0.346979  ...   4    1   0    0    1\n",
              "4    0.301532 -1.307875 -0.537064 -0.586231 -0.329317  ...   2    0   0    0    0\n",
              "..        ...       ...       ...       ...       ...  ...  ..  ...  ..  ...  ...\n",
              "346  0.301532  0.448300 -0.093267 -0.108432 -0.582927  ...   0    0   0    0    0\n",
              "347 -0.454452  1.326387 -0.941702 -0.482362 -0.385674  ...   0    0   0    0    0\n",
              "348  0.301532  0.448300 -0.615381 -0.586231 -0.554748  ...   0    0   0    0    0\n",
              "349 -1.210437  1.326387 -0.432641 -0.087659 -0.442032  ...   0    0   0    0    0\n",
              "350  0.301532  1.326387 -0.210742 -0.752422 -0.413853  ...   0    0   0    0    0\n",
              "\n",
              "[351 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjqzOLVUbIKT"
      },
      "source": [
        "y= dt.iloc[:,-1]\n",
        "\n",
        "def_encoder = LabelEncoder()\n",
        "y = def_encoder.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haBaOUIy1cZs"
      },
      "source": [
        "#pisah data train & data test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42) #kenapa 42?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyyvB--A6wVd"
      },
      "source": [
        "# **Melatih Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5XiySrxIG5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b81aa1-0f7a-4310-a3fa-9f5c7b3f97fc"
      },
      "source": [
        "random.seed(69)\n",
        "\n",
        "def create_model(learn_rate, hidden_layers, neurons):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(14))\n",
        "  for i in range(hidden_layers):\n",
        "    model.add(Dense(neurons, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  optimizer = SGD(learning_rate=learn_rate)\n",
        "  model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        " \n",
        "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "param_grid = {\"hidden_layers\": [1,2,3,4,5], \"neurons\": [1,2,3,5,6,7,8,9,10,11,12,13,14], \"learn_rate\": [0.0001, 0.001, 0.01, 0.1, 1]}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        " \n",
        "print(\"Akurasi terbaik: %f menggunakan %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"Akurasi: %f (%f) dengan: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi terbaik: 0.996429 menggunakan {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 2}\n",
            "Akurasi: 0.557143 (0.179427) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 1}\n",
            "Akurasi: 0.521429 (0.232664) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 2}\n",
            "Akurasi: 0.489286 (0.193682) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 3}\n",
            "Akurasi: 0.489286 (0.192360) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 5}\n",
            "Akurasi: 0.521429 (0.224858) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 6}\n",
            "Akurasi: 0.589286 (0.143969) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 7}\n",
            "Akurasi: 0.485714 (0.172171) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 8}\n",
            "Akurasi: 0.542857 (0.191530) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 9}\n",
            "Akurasi: 0.446429 (0.237036) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 10}\n",
            "Akurasi: 0.571429 (0.183503) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 11}\n",
            "Akurasi: 0.617857 (0.189016) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 12}\n",
            "Akurasi: 0.482143 (0.268333) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 13}\n",
            "Akurasi: 0.542857 (0.157143) dengan: {'hidden_layers': 1, 'learn_rate': 0.0001, 'neurons': 14}\n",
            "Akurasi: 0.428571 (0.220158) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 1}\n",
            "Akurasi: 0.585714 (0.213809) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 2}\n",
            "Akurasi: 0.625000 (0.202818) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 3}\n",
            "Akurasi: 0.664286 (0.143036) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 5}\n",
            "Akurasi: 0.710714 (0.164014) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 6}\n",
            "Akurasi: 0.678571 (0.236902) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 7}\n",
            "Akurasi: 0.507143 (0.147080) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 8}\n",
            "Akurasi: 0.596429 (0.165253) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 9}\n",
            "Akurasi: 0.607143 (0.216654) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 10}\n",
            "Akurasi: 0.525000 (0.199521) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 11}\n",
            "Akurasi: 0.592857 (0.122890) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 12}\n",
            "Akurasi: 0.464286 (0.196915) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 13}\n",
            "Akurasi: 0.557143 (0.155018) dengan: {'hidden_layers': 1, 'learn_rate': 0.001, 'neurons': 14}\n",
            "Akurasi: 0.707143 (0.184750) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 1}\n",
            "Akurasi: 0.882143 (0.132721) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 2}\n",
            "Akurasi: 0.885714 (0.082685) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 3}\n",
            "Akurasi: 0.882143 (0.167553) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 5}\n",
            "Akurasi: 0.953571 (0.045316) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 6}\n",
            "Akurasi: 0.914286 (0.116496) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 7}\n",
            "Akurasi: 0.903571 (0.127825) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 8}\n",
            "Akurasi: 0.896429 (0.083681) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 9}\n",
            "Akurasi: 0.935714 (0.059333) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 10}\n",
            "Akurasi: 0.942857 (0.062270) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 11}\n",
            "Akurasi: 0.907143 (0.062270) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 12}\n",
            "Akurasi: 0.935714 (0.079539) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 13}\n",
            "Akurasi: 0.950000 (0.058029) dengan: {'hidden_layers': 1, 'learn_rate': 0.01, 'neurons': 14}\n",
            "Akurasi: 0.978571 (0.023690) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 1}\n",
            "Akurasi: 0.982143 (0.023958) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 2}\n",
            "Akurasi: 0.985714 (0.023690) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 3}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 5}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 6}\n",
            "Akurasi: 0.985714 (0.023690) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 7}\n",
            "Akurasi: 0.975000 (0.022868) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 8}\n",
            "Akurasi: 0.978571 (0.032733) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 9}\n",
            "Akurasi: 0.982143 (0.023958) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 10}\n",
            "Akurasi: 0.978571 (0.017496) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 11}\n",
            "Akurasi: 0.982143 (0.023958) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 12}\n",
            "Akurasi: 0.978571 (0.023690) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 13}\n",
            "Akurasi: 0.975000 (0.022868) dengan: {'hidden_layers': 1, 'learn_rate': 0.1, 'neurons': 14}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 1}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 2}\n",
            "Akurasi: 0.985714 (0.023690) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 3}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 5}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 6}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 7}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 8}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 9}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 10}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 11}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 12}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 13}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 1, 'learn_rate': 1, 'neurons': 14}\n",
            "Akurasi: 0.571429 (0.091752) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 1}\n",
            "Akurasi: 0.564286 (0.095565) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 2}\n",
            "Akurasi: 0.575000 (0.117857) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 3}\n",
            "Akurasi: 0.396429 (0.199137) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 5}\n",
            "Akurasi: 0.514286 (0.114286) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 6}\n",
            "Akurasi: 0.453571 (0.065951) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 7}\n",
            "Akurasi: 0.585714 (0.148290) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 8}\n",
            "Akurasi: 0.532143 (0.223863) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 9}\n",
            "Akurasi: 0.496429 (0.134059) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 10}\n",
            "Akurasi: 0.592857 (0.137581) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 11}\n",
            "Akurasi: 0.589286 (0.147470) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 12}\n",
            "Akurasi: 0.542857 (0.192857) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 13}\n",
            "Akurasi: 0.485714 (0.211409) dengan: {'hidden_layers': 2, 'learn_rate': 0.0001, 'neurons': 14}\n",
            "Akurasi: 0.546429 (0.260519) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 1}\n",
            "Akurasi: 0.539286 (0.181019) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 2}\n",
            "Akurasi: 0.571429 (0.108327) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 3}\n",
            "Akurasi: 0.539286 (0.242463) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 5}\n",
            "Akurasi: 0.596429 (0.200796) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 6}\n",
            "Akurasi: 0.514286 (0.175836) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 7}\n",
            "Akurasi: 0.610714 (0.221573) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 8}\n",
            "Akurasi: 0.539286 (0.116770) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 9}\n",
            "Akurasi: 0.485714 (0.164596) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 10}\n",
            "Akurasi: 0.582143 (0.122735) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 11}\n",
            "Akurasi: 0.560714 (0.154895) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 12}\n",
            "Akurasi: 0.525000 (0.107202) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 13}\n",
            "Akurasi: 0.596429 (0.158154) dengan: {'hidden_layers': 2, 'learn_rate': 0.001, 'neurons': 14}\n",
            "Akurasi: 0.600000 (0.117152) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 1}\n",
            "Akurasi: 0.575000 (0.126219) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 2}\n",
            "Akurasi: 0.700000 (0.142141) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 3}\n",
            "Akurasi: 0.846429 (0.081519) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 5}\n",
            "Akurasi: 0.753571 (0.190629) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 6}\n",
            "Akurasi: 0.875000 (0.121900) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 7}\n",
            "Akurasi: 0.850000 (0.143570) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 8}\n",
            "Akurasi: 0.875000 (0.131950) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 9}\n",
            "Akurasi: 0.882143 (0.079939) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 10}\n",
            "Akurasi: 0.903571 (0.075000) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 11}\n",
            "Akurasi: 0.860714 (0.127225) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 12}\n",
            "Akurasi: 0.882143 (0.130785) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 13}\n",
            "Akurasi: 0.914286 (0.114286) dengan: {'hidden_layers': 2, 'learn_rate': 0.01, 'neurons': 14}\n",
            "Akurasi: 0.739286 (0.217857) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 1}\n",
            "Akurasi: 0.942857 (0.102519) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 2}\n",
            "Akurasi: 0.889286 (0.169370) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 3}\n",
            "Akurasi: 0.985714 (0.017496) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 5}\n",
            "Akurasi: 0.971429 (0.031135) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 6}\n",
            "Akurasi: 0.975000 (0.022868) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 7}\n",
            "Akurasi: 0.975000 (0.022868) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 8}\n",
            "Akurasi: 0.982143 (0.017857) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 9}\n",
            "Akurasi: 0.971429 (0.034993) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 10}\n",
            "Akurasi: 0.982143 (0.023958) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 11}\n",
            "Akurasi: 0.975000 (0.032143) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 12}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 13}\n",
            "Akurasi: 0.985714 (0.017496) dengan: {'hidden_layers': 2, 'learn_rate': 0.1, 'neurons': 14}\n",
            "Akurasi: 0.750000 (0.205784) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 1}\n",
            "Akurasi: 0.967857 (0.073973) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 2}\n",
            "Akurasi: 0.989286 (0.022868) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 3}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 5}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 6}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 7}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 8}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 9}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 10}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 11}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 12}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 13}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 2, 'learn_rate': 1, 'neurons': 14}\n",
            "Akurasi: 0.560714 (0.101078) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 1}\n",
            "Akurasi: 0.528571 (0.108091) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 2}\n",
            "Akurasi: 0.532143 (0.088135) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 3}\n",
            "Akurasi: 0.492857 (0.205660) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 5}\n",
            "Akurasi: 0.514286 (0.210199) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 6}\n",
            "Akurasi: 0.510714 (0.109556) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 7}\n",
            "Akurasi: 0.521429 (0.092029) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 8}\n",
            "Akurasi: 0.425000 (0.141466) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 9}\n",
            "Akurasi: 0.467857 (0.135949) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 10}\n",
            "Akurasi: 0.489286 (0.109556) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 11}\n",
            "Akurasi: 0.521429 (0.147427) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 12}\n",
            "Akurasi: 0.453571 (0.214315) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 13}\n",
            "Akurasi: 0.432143 (0.135949) dengan: {'hidden_layers': 3, 'learn_rate': 0.0001, 'neurons': 14}\n",
            "Akurasi: 0.514286 (0.167667) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 1}\n",
            "Akurasi: 0.639286 (0.206681) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 2}\n",
            "Akurasi: 0.485714 (0.166905) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 3}\n",
            "Akurasi: 0.425000 (0.075677) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 5}\n",
            "Akurasi: 0.560714 (0.162921) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 6}\n",
            "Akurasi: 0.500000 (0.209470) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 7}\n",
            "Akurasi: 0.471429 (0.182667) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 8}\n",
            "Akurasi: 0.557143 (0.231014) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 9}\n",
            "Akurasi: 0.453571 (0.160555) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 10}\n",
            "Akurasi: 0.535714 (0.135526) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 11}\n",
            "Akurasi: 0.453571 (0.168312) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 12}\n",
            "Akurasi: 0.525000 (0.132721) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 13}\n",
            "Akurasi: 0.560714 (0.173536) dengan: {'hidden_layers': 3, 'learn_rate': 0.001, 'neurons': 14}\n",
            "Akurasi: 0.571429 (0.091752) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 1}\n",
            "Akurasi: 0.560714 (0.069712) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 2}\n",
            "Akurasi: 0.646429 (0.158476) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 3}\n",
            "Akurasi: 0.725000 (0.217857) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 5}\n",
            "Akurasi: 0.667857 (0.147297) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 6}\n",
            "Akurasi: 0.735714 (0.169934) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 7}\n",
            "Akurasi: 0.725000 (0.158154) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 8}\n",
            "Akurasi: 0.746429 (0.151059) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 9}\n",
            "Akurasi: 0.735714 (0.157467) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 10}\n",
            "Akurasi: 0.764286 (0.136651) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 11}\n",
            "Akurasi: 0.842857 (0.132865) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 12}\n",
            "Akurasi: 0.782143 (0.114564) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 13}\n",
            "Akurasi: 0.778571 (0.165831) dengan: {'hidden_layers': 3, 'learn_rate': 0.01, 'neurons': 14}\n",
            "Akurasi: 0.625000 (0.150890) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 1}\n",
            "Akurasi: 0.764286 (0.234303) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 2}\n",
            "Akurasi: 0.939286 (0.103571) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 3}\n",
            "Akurasi: 0.982143 (0.032927) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 5}\n",
            "Akurasi: 0.978571 (0.023690) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 6}\n",
            "Akurasi: 0.982143 (0.032927) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 7}\n",
            "Akurasi: 0.985714 (0.017496) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 8}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 9}\n",
            "Akurasi: 0.982143 (0.023958) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 10}\n",
            "Akurasi: 0.978571 (0.023690) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 11}\n",
            "Akurasi: 0.975000 (0.022868) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 12}\n",
            "Akurasi: 0.978571 (0.023690) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 13}\n",
            "Akurasi: 0.985714 (0.032733) dengan: {'hidden_layers': 3, 'learn_rate': 0.1, 'neurons': 14}\n",
            "Akurasi: 0.692857 (0.216771) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 1}\n",
            "Akurasi: 0.821429 (0.208860) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 2}\n",
            "Akurasi: 0.942857 (0.159879) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 3}\n",
            "Akurasi: 0.989286 (0.022868) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 5}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 6}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 7}\n",
            "Akurasi: 0.946429 (0.149190) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 8}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 9}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 10}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 11}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 12}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 13}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 3, 'learn_rate': 1, 'neurons': 14}\n",
            "Akurasi: 0.592857 (0.118666) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 1}\n",
            "Akurasi: 0.585714 (0.084817) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 2}\n",
            "Akurasi: 0.535714 (0.185577) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 3}\n",
            "Akurasi: 0.632143 (0.156533) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 5}\n",
            "Akurasi: 0.482143 (0.086381) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 6}\n",
            "Akurasi: 0.478571 (0.093405) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 7}\n",
            "Akurasi: 0.482143 (0.144852) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 8}\n",
            "Akurasi: 0.571429 (0.140153) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 9}\n",
            "Akurasi: 0.546429 (0.162137) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 10}\n",
            "Akurasi: 0.564286 (0.151354) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 11}\n",
            "Akurasi: 0.646429 (0.144146) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 12}\n",
            "Akurasi: 0.435714 (0.163507) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 13}\n",
            "Akurasi: 0.496429 (0.131174) dengan: {'hidden_layers': 4, 'learn_rate': 0.0001, 'neurons': 14}\n",
            "Akurasi: 0.514286 (0.131901) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 1}\n",
            "Akurasi: 0.660714 (0.152571) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 2}\n",
            "Akurasi: 0.575000 (0.112316) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 3}\n",
            "Akurasi: 0.617857 (0.119576) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 5}\n",
            "Akurasi: 0.446429 (0.169219) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 6}\n",
            "Akurasi: 0.542857 (0.184059) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 7}\n",
            "Akurasi: 0.471429 (0.125560) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 8}\n",
            "Akurasi: 0.557143 (0.143925) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 9}\n",
            "Akurasi: 0.567857 (0.100318) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 10}\n",
            "Akurasi: 0.625000 (0.112088) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 11}\n",
            "Akurasi: 0.464286 (0.129756) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 12}\n",
            "Akurasi: 0.610714 (0.113446) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 13}\n",
            "Akurasi: 0.467857 (0.211560) dengan: {'hidden_layers': 4, 'learn_rate': 0.001, 'neurons': 14}\n",
            "Akurasi: 0.610714 (0.129215) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 1}\n",
            "Akurasi: 0.650000 (0.169633) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 2}\n",
            "Akurasi: 0.589286 (0.140380) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 3}\n",
            "Akurasi: 0.703571 (0.189016) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 5}\n",
            "Akurasi: 0.660714 (0.129017) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 6}\n",
            "Akurasi: 0.657143 (0.191796) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 7}\n",
            "Akurasi: 0.635714 (0.106904) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 8}\n",
            "Akurasi: 0.689286 (0.153239) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 9}\n",
            "Akurasi: 0.825000 (0.149361) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 10}\n",
            "Akurasi: 0.660714 (0.157508) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 11}\n",
            "Akurasi: 0.739286 (0.179320) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 12}\n",
            "Akurasi: 0.689286 (0.143792) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 13}\n",
            "Akurasi: 0.725000 (0.167553) dengan: {'hidden_layers': 4, 'learn_rate': 0.01, 'neurons': 14}\n",
            "Akurasi: 0.571429 (0.091752) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 1}\n",
            "Akurasi: 0.667857 (0.177892) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 2}\n",
            "Akurasi: 0.789286 (0.202314) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 3}\n",
            "Akurasi: 0.932143 (0.134059) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 5}\n",
            "Akurasi: 0.989286 (0.022868) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 6}\n",
            "Akurasi: 0.985714 (0.017496) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 7}\n",
            "Akurasi: 0.978571 (0.023690) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 8}\n",
            "Akurasi: 0.982143 (0.017857) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 9}\n",
            "Akurasi: 0.992857 (0.014286) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 10}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 11}\n",
            "Akurasi: 0.975000 (0.032143) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 12}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 13}\n",
            "Akurasi: 0.978571 (0.023690) dengan: {'hidden_layers': 4, 'learn_rate': 0.1, 'neurons': 14}\n",
            "Akurasi: 0.571429 (0.091752) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 1}\n",
            "Akurasi: 0.742857 (0.218879) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 2}\n",
            "Akurasi: 0.871429 (0.192460) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 3}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 5}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 6}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 7}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 8}\n",
            "Akurasi: 0.885714 (0.166599) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 9}\n",
            "Akurasi: 0.964286 (0.074915) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 10}\n",
            "Akurasi: 0.985714 (0.017496) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 11}\n",
            "Akurasi: 0.985714 (0.023690) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 12}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 13}\n",
            "Akurasi: 0.825000 (0.254275) dengan: {'hidden_layers': 4, 'learn_rate': 1, 'neurons': 14}\n",
            "Akurasi: 0.571429 (0.091752) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 1}\n",
            "Akurasi: 0.578571 (0.096890) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 2}\n",
            "Akurasi: 0.560714 (0.157346) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 3}\n",
            "Akurasi: 0.503571 (0.126219) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 5}\n",
            "Akurasi: 0.557143 (0.208982) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 6}\n",
            "Akurasi: 0.514286 (0.130931) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 7}\n",
            "Akurasi: 0.550000 (0.193122) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 8}\n",
            "Akurasi: 0.507143 (0.193517) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 9}\n",
            "Akurasi: 0.510714 (0.153239) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 10}\n",
            "Akurasi: 0.535714 (0.123718) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 11}\n",
            "Akurasi: 0.553571 (0.167705) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 12}\n",
            "Akurasi: 0.532143 (0.181722) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 13}\n",
            "Akurasi: 0.421429 (0.190863) dengan: {'hidden_layers': 5, 'learn_rate': 0.0001, 'neurons': 14}\n",
            "Akurasi: 0.571429 (0.091752) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 1}\n",
            "Akurasi: 0.557143 (0.090633) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 2}\n",
            "Akurasi: 0.453571 (0.228153) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 3}\n",
            "Akurasi: 0.507143 (0.238405) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 5}\n",
            "Akurasi: 0.514286 (0.098716) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 6}\n",
            "Akurasi: 0.567857 (0.178178) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 7}\n",
            "Akurasi: 0.532143 (0.150212) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 8}\n",
            "Akurasi: 0.414286 (0.103756) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 9}\n",
            "Akurasi: 0.575000 (0.095097) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 10}\n",
            "Akurasi: 0.467857 (0.121060) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 11}\n",
            "Akurasi: 0.514286 (0.210199) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 12}\n",
            "Akurasi: 0.417857 (0.131756) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 13}\n",
            "Akurasi: 0.482143 (0.175146) dengan: {'hidden_layers': 5, 'learn_rate': 0.001, 'neurons': 14}\n",
            "Akurasi: 0.571429 (0.091752) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 1}\n",
            "Akurasi: 0.596429 (0.144676) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 2}\n",
            "Akurasi: 0.621429 (0.134771) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 3}\n",
            "Akurasi: 0.725000 (0.154895) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 5}\n",
            "Akurasi: 0.685714 (0.180560) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 6}\n",
            "Akurasi: 0.696429 (0.134818) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 7}\n",
            "Akurasi: 0.721429 (0.143570) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 8}\n",
            "Akurasi: 0.582143 (0.089000) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 9}\n",
            "Akurasi: 0.596429 (0.110714) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 10}\n",
            "Akurasi: 0.639286 (0.148504) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 11}\n",
            "Akurasi: 0.735714 (0.122890) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 12}\n",
            "Akurasi: 0.700000 (0.156655) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 13}\n",
            "Akurasi: 0.664286 (0.175836) dengan: {'hidden_layers': 5, 'learn_rate': 0.01, 'neurons': 14}\n",
            "Akurasi: 0.603571 (0.156859) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 1}\n",
            "Akurasi: 0.689286 (0.214315) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 2}\n",
            "Akurasi: 0.782143 (0.202314) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 3}\n",
            "Akurasi: 0.860714 (0.187253) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 5}\n",
            "Akurasi: 0.885714 (0.188171) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 6}\n",
            "Akurasi: 0.982143 (0.017857) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 7}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 8}\n",
            "Akurasi: 0.982143 (0.017857) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 9}\n",
            "Akurasi: 0.964286 (0.031944) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 10}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 11}\n",
            "Akurasi: 0.985714 (0.017496) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 12}\n",
            "Akurasi: 0.985714 (0.017496) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 13}\n",
            "Akurasi: 0.989286 (0.022868) dengan: {'hidden_layers': 5, 'learn_rate': 0.1, 'neurons': 14}\n",
            "Akurasi: 0.621429 (0.142141) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 1}\n",
            "Akurasi: 0.610714 (0.149361) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 2}\n",
            "Akurasi: 0.835714 (0.236471) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 3}\n",
            "Akurasi: 0.903571 (0.180030) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 5}\n",
            "Akurasi: 0.989286 (0.016366) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 6}\n",
            "Akurasi: 0.982143 (0.023958) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 7}\n",
            "Akurasi: 0.950000 (0.126974) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 8}\n",
            "Akurasi: 0.939286 (0.158959) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 9}\n",
            "Akurasi: 0.942857 (0.159879) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 10}\n",
            "Akurasi: 0.889286 (0.188611) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 11}\n",
            "Akurasi: 0.914286 (0.139423) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 12}\n",
            "Akurasi: 0.853571 (0.218675) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 13}\n",
            "Akurasi: 0.996429 (0.010714) dengan: {'hidden_layers': 5, 'learn_rate': 1, 'neurons': 14}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUv6-V4drao-"
      },
      "source": [
        "# **Model dengan Parameter Terbaik**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2unKOxRhtirD",
        "outputId": "e7c9d1cc-488d-4915-d3b1-9e9db4dc7d4e"
      },
      "source": [
        "print(grid_result.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hidden_layers': 1, 'learn_rate': 1, 'neurons': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOsgVckItoUD",
        "outputId": "c347cda0-8004-4584-a612-f9f3f0104fc7"
      },
      "source": [
        "y_pred= grid_result.predict(X_test)\n",
        "print('Akurasi:',metrics.accuracy_score(y_pred,y_test))\n",
        "print('Presisi:',metrics.precision_score(y_pred,y_test))\n",
        "print('Recall:',metrics.recall_score(y_pred,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi: 0.971830985915493\n",
            "Presisi: 0.9782608695652174\n",
            "Recall: 0.9782608695652174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "-8ee5D9nNcdZ",
        "outputId": "ec4fccf7-3148-41c1-9db9-e75fcbba678b"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bp</th>\n",
              "      <th>sg</th>\n",
              "      <th>bgr</th>\n",
              "      <th>bu</th>\n",
              "      <th>sc</th>\n",
              "      <th>hemo</th>\n",
              "      <th>pcv</th>\n",
              "      <th>wc</th>\n",
              "      <th>rc</th>\n",
              "      <th>al</th>\n",
              "      <th>htn</th>\n",
              "      <th>dm</th>\n",
              "      <th>cad</th>\n",
              "      <th>ane</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>-0.454452</td>\n",
              "      <td>-1.307875</td>\n",
              "      <td>-0.328218</td>\n",
              "      <td>-0.669327</td>\n",
              "      <td>-0.526569</td>\n",
              "      <td>-0.778534</td>\n",
              "      <td>-0.615585</td>\n",
              "      <td>1.298203</td>\n",
              "      <td>-0.631136</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>0.301532</td>\n",
              "      <td>1.326387</td>\n",
              "      <td>-0.811173</td>\n",
              "      <td>-0.793970</td>\n",
              "      <td>-0.413853</td>\n",
              "      <td>1.076294</td>\n",
              "      <td>0.606227</td>\n",
              "      <td>-0.191667</td>\n",
              "      <td>1.857052</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>0.301532</td>\n",
              "      <td>0.448300</td>\n",
              "      <td>-0.706751</td>\n",
              "      <td>-0.170754</td>\n",
              "      <td>-0.442032</td>\n",
              "      <td>-0.097168</td>\n",
              "      <td>-0.080654</td>\n",
              "      <td>0.931466</td>\n",
              "      <td>1.857052</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>-0.454452</td>\n",
              "      <td>1.326387</td>\n",
              "      <td>-0.093267</td>\n",
              "      <td>-0.648553</td>\n",
              "      <td>-0.554748</td>\n",
              "      <td>1.341270</td>\n",
              "      <td>1.094951</td>\n",
              "      <td>-0.191667</td>\n",
              "      <td>1.075898</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>-0.454452</td>\n",
              "      <td>0.448300</td>\n",
              "      <td>-0.628434</td>\n",
              "      <td>-0.648553</td>\n",
              "      <td>-0.554748</td>\n",
              "      <td>-0.286437</td>\n",
              "      <td>-0.615585</td>\n",
              "      <td>-1.519256</td>\n",
              "      <td>-0.239937</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>1.057517</td>\n",
              "      <td>-1.307875</td>\n",
              "      <td>1.185913</td>\n",
              "      <td>0.057758</td>\n",
              "      <td>-0.019348</td>\n",
              "      <td>-1.119217</td>\n",
              "      <td>-1.348672</td>\n",
              "      <td>0.312597</td>\n",
              "      <td>-1.490752</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>1.813502</td>\n",
              "      <td>-1.307875</td>\n",
              "      <td>-0.902543</td>\n",
              "      <td>0.140854</td>\n",
              "      <td>-0.216601</td>\n",
              "      <td>-0.210729</td>\n",
              "      <td>-0.371223</td>\n",
              "      <td>0.885624</td>\n",
              "      <td>-0.374817</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>-0.454452</td>\n",
              "      <td>-1.307875</td>\n",
              "      <td>0.872645</td>\n",
              "      <td>0.867939</td>\n",
              "      <td>1.051453</td>\n",
              "      <td>-1.270631</td>\n",
              "      <td>-1.348672</td>\n",
              "      <td>1.114834</td>\n",
              "      <td>-1.490752</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>-0.454452</td>\n",
              "      <td>1.326387</td>\n",
              "      <td>-0.772015</td>\n",
              "      <td>-0.793970</td>\n",
              "      <td>-0.413853</td>\n",
              "      <td>1.379123</td>\n",
              "      <td>1.705857</td>\n",
              "      <td>0.564728</td>\n",
              "      <td>0.629524</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>0.301532</td>\n",
              "      <td>0.448300</td>\n",
              "      <td>-0.680645</td>\n",
              "      <td>-0.399266</td>\n",
              "      <td>-0.470211</td>\n",
              "      <td>-0.097168</td>\n",
              "      <td>-0.080654</td>\n",
              "      <td>-1.519256</td>\n",
              "      <td>-0.089477</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           bp        sg       bgr        bu        sc  ...  al  htn  dm  cad  ane\n",
              "157 -0.454452 -1.307875 -0.328218 -0.669327 -0.526569  ...   2    0   0    0    0\n",
              "342  0.301532  1.326387 -0.811173 -0.793970 -0.413853  ...   0    0   0    0    0\n",
              "316  0.301532  0.448300 -0.706751 -0.170754 -0.442032  ...   0    0   0    0    0\n",
              "234 -0.454452  1.326387 -0.093267 -0.648553 -0.554748  ...   0    0   0    0    0\n",
              "155 -0.454452  0.448300 -0.628434 -0.648553 -0.554748  ...   1    0   0    0    0\n",
              "..        ...       ...       ...       ...       ...  ...  ..  ...  ..  ...  ...\n",
              "181  1.057517 -1.307875  1.185913  0.057758 -0.019348  ...   0    1   1    0    0\n",
              "179  1.813502 -1.307875 -0.902543  0.140854 -0.216601  ...   1    0   1    0    0\n",
              "199 -0.454452 -1.307875  0.872645  0.867939  1.051453  ...   4    1   1    1    1\n",
              "327 -0.454452  1.326387 -0.772015 -0.793970 -0.413853  ...   0    0   0    0    0\n",
              "228  0.301532  0.448300 -0.680645 -0.399266 -0.470211  ...   0    0   0    0    0\n",
              "\n",
              "[71 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkMXoe4UuuUt"
      },
      "source": [
        "#coba pake data-data\n",
        "dt2 = pd.read_csv('https://raw.githubusercontent.com/Syamsyuriani/CKD/main/DatasetPGK(Processed).csv')\n",
        "X2 = dt2.drop(columns=['age', 'su', 'pc', 'pcc', 'ba', 'sod', 'pot', 'appet', 'pe', 'classification'])\n",
        "cols = list(X_test.columns.values)\n",
        "X2 = X2[cols]\n",
        "y2 = dt2.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdc_Me2-vNME",
        "outputId": "20d0193a-708d-4b62-be26-7fbf04e903e5"
      },
      "source": [
        "y2_pred= grid.predict(X2)\n",
        "print('Akurasi:',metrics.accuracy_score(y2_pred,y2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi: 0.5868945868945868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "00j1kmnIVuPL",
        "outputId": "ecbadca6-80e4-4d15-fc7a-8c289ba8d6a9"
      },
      "source": [
        "cm_mlp = confusion_matrix(y_test, y_pred)\n",
        "cm_mlp\n",
        " \n",
        "cm_display = ConfusionMatrixDisplay(cm_mlp, display_labels= ['negative','positive']).plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuNpRWJlXhld",
        "outputId": "b4068f0d-833f-4c22-e8d0-33e557c840e4"
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "(tn, fp, fn, tp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 1, 1, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9OwkLmTVJgb"
      },
      "source": [
        "# **Rata-rata**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwAJZZKSVOm0",
        "outputId": "f9798d9d-e617-4ab6-ce8b-f2efc080bd79"
      },
      "source": [
        "akurasi = [None]*10\n",
        "presisi = [None]*10\n",
        "recall = [None]*10\n",
        "\n",
        "for i in range(10):\n",
        "  dt = pd.read_csv('https://raw.githubusercontent.com/Syamsyuriani/CKD/main/DatasetPGK(Processed).csv')\n",
        "  X = dt.drop(columns=['age', 'su', 'pc', 'pcc', 'ba', 'sod', 'pot', 'appet', 'pe', 'classification'])\n",
        "  \n",
        "  #Pisah data numerik\n",
        "  var_kategorik = ['al', 'htn', 'dm', 'cad', 'ane']\n",
        "  X_numerik = X.drop(columns=var_kategorik)\n",
        "  X_kategorik = X[var_kategorik]\n",
        "\n",
        "  #Standarisasi yang numerik\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X_numerik)\n",
        "  X_numerik = scaler.transform(X_numerik)\n",
        "\n",
        "  #gabung X_numerik & X_kategorik\n",
        "  X_numerik = pd.DataFrame(X_numerik)\n",
        "  X = pd.concat([X_numerik, X_kategorik], axis=1)\n",
        "  X.rename(\n",
        "    columns=({ 0: 'bp', 1: 'sg', 2: 'bgr', 3: 'bu', 4: 'sc', 5: 'hemo', 6: 'pcv', 7: 'wc', 8: 'rc'}), \n",
        "    inplace=True,\n",
        "  )\n",
        "\n",
        "  y= dt.iloc[:,-1]\n",
        "  def_encoder = LabelEncoder()\n",
        "  y = def_encoder.fit_transform(y)  \n",
        "\n",
        "  #pisah data train & data test\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(14))\n",
        "  for j in range(1): #################### jumlah hidden layer ####################\n",
        "    model.add(Dense(2, activation='relu')) ###################### jumlah neuron ########################\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  optimizer = SGD(learning_rate=1) ################## learning rate #######################\n",
        "  model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train, y_train, batch_size=32, epochs = 10, validation_data = (X_train, y_train))\n",
        "\n",
        "  y_pred = model.predict_classes(X_test)\n",
        "\n",
        "  TP = 0\n",
        "  FP = 0\n",
        "  TN = 0\n",
        "  FN = 0\n",
        "  for k in range(len(y_pred)):\n",
        "    if y_pred[k] == 1 and y_test[k] == 1:\n",
        "      TP += 1\n",
        "    if y_pred[k] == 1 and y_test[k] == 0:\n",
        "      FP += 1\n",
        "    if y_pred[k] == 0 and y_test[k] == 0:\n",
        "      TN += 1\n",
        "    if y_pred[k] == 0 and y_test[k] == 1:\n",
        "      FN += 1\n",
        "  \n",
        "  akurasi[i] = (TP + TN) / len(y_pred)\n",
        "  presisi[i] = (TP) / (TP + FP)\n",
        "  recall[i]= (TP) / (TP + FN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 1s 24ms/step - loss: 0.1705 - accuracy: 0.9429 - val_loss: 0.0470 - val_accuracy: 0.9857\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9821 - val_loss: 0.0324 - val_accuracy: 0.9857\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9857 - val_loss: 0.0256 - val_accuracy: 0.9857\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9893 - val_loss: 0.0235 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9893 - val_loss: 0.0216 - val_accuracy: 0.9929\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9821 - val_loss: 0.0206 - val_accuracy: 0.9893\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9893 - val_loss: 0.0239 - val_accuracy: 0.9857\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9893 - val_loss: 0.0193 - val_accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9929 - val_loss: 0.0178 - val_accuracy: 0.9929\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9893 - val_loss: 0.0177 - val_accuracy: 0.9893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 1s 35ms/step - loss: 0.3145 - accuracy: 0.9071 - val_loss: 0.1488 - val_accuracy: 0.9857\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9857 - val_loss: 0.0848 - val_accuracy: 0.9893\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 0.9893 - val_loss: 0.0619 - val_accuracy: 0.9929\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9929 - val_loss: 0.0484 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9893 - val_loss: 0.0431 - val_accuracy: 0.9929\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9893 - val_loss: 0.0394 - val_accuracy: 0.9893\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9893 - val_loss: 0.0347 - val_accuracy: 0.9929\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9893 - val_loss: 0.0463 - val_accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9929 - val_loss: 0.0283 - val_accuracy: 0.9893\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 0.0587 - val_accuracy: 0.9821\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 19ms/step - loss: 0.2459 - accuracy: 0.8607 - val_loss: 0.0701 - val_accuracy: 0.9750\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9821 - val_loss: 0.0375 - val_accuracy: 0.9857\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9893 - val_loss: 0.0251 - val_accuracy: 0.9929\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9929 - val_loss: 0.0206 - val_accuracy: 0.9964\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9964 - val_loss: 0.0177 - val_accuracy: 0.9964\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9964 - val_loss: 0.0168 - val_accuracy: 0.9964\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9964 - val_loss: 0.0148 - val_accuracy: 0.9964\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 0.0126 - val_accuracy: 0.9964\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.0113 - val_accuracy: 0.9964\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.0106 - val_accuracy: 0.9964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.3488 - accuracy: 0.9000 - val_loss: 0.1614 - val_accuracy: 0.9821\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1302 - accuracy: 0.9786 - val_loss: 0.0938 - val_accuracy: 0.9857\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9893 - val_loss: 0.0660 - val_accuracy: 0.9821\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9857 - val_loss: 0.0535 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9857 - val_loss: 0.0484 - val_accuracy: 0.9857\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9893 - val_loss: 0.0446 - val_accuracy: 0.9857\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9786 - val_loss: 0.0370 - val_accuracy: 0.9893\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 0.0339 - val_accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.0331 - val_accuracy: 0.9893\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9821 - val_loss: 0.0307 - val_accuracy: 0.9893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 1s 21ms/step - loss: 0.2224 - accuracy: 0.9143 - val_loss: 0.0494 - val_accuracy: 0.9929\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9893 - val_loss: 0.0332 - val_accuracy: 0.9893\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9893 - val_loss: 0.0295 - val_accuracy: 0.9893\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9893 - val_loss: 0.0201 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9893 - val_loss: 0.0250 - val_accuracy: 0.9893\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9857 - val_loss: 0.0210 - val_accuracy: 0.9929\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.0185 - val_accuracy: 0.9929\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9893 - val_loss: 0.0153 - val_accuracy: 0.9929\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9857 - val_loss: 0.0243 - val_accuracy: 0.9893\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9893 - val_loss: 0.0274 - val_accuracy: 0.9893\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdb31454e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.3688 - accuracy: 0.8714 - val_loss: 0.1845 - val_accuracy: 0.9893\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9821 - val_loss: 0.1051 - val_accuracy: 0.9893\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9857 - val_loss: 0.0733 - val_accuracy: 0.9929\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9893 - val_loss: 0.0558 - val_accuracy: 0.9929\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9893 - val_loss: 0.0509 - val_accuracy: 0.9929\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9857 - val_loss: 0.0390 - val_accuracy: 0.9893\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9893 - val_loss: 0.0411 - val_accuracy: 0.9893\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.9964 - val_loss: 0.0370 - val_accuracy: 0.9929\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9893 - val_loss: 0.0434 - val_accuracy: 0.9893\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9964 - val_loss: 0.0280 - val_accuracy: 0.9893\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdb2d8ad8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 0.2591 - accuracy: 0.8500 - val_loss: 0.0655 - val_accuracy: 0.9786\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9786 - val_loss: 0.0324 - val_accuracy: 0.9857\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.0401 - val_accuracy: 0.9857\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9929 - val_loss: 0.0218 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.0180 - val_accuracy: 0.9964\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9857 - val_loss: 0.0319 - val_accuracy: 0.9893\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9893 - val_loss: 0.0148 - val_accuracy: 0.9964\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9929 - val_loss: 0.0222 - val_accuracy: 0.9857\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0268 - val_accuracy: 0.9893\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9929 - val_loss: 0.0158 - val_accuracy: 0.9893\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 19ms/step - loss: 0.1849 - accuracy: 0.9286 - val_loss: 0.0404 - val_accuracy: 0.9857\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9786 - val_loss: 0.0254 - val_accuracy: 0.9893\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9929 - val_loss: 0.0216 - val_accuracy: 0.9929\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9893 - val_loss: 0.0209 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9857 - val_loss: 0.0173 - val_accuracy: 0.9893\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9857 - val_loss: 0.0175 - val_accuracy: 0.9893\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9929 - val_loss: 0.0242 - val_accuracy: 0.9893\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0162 - val_accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9929 - val_loss: 0.0235 - val_accuracy: 0.9893\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9857 - val_loss: 0.0165 - val_accuracy: 0.9929\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 18ms/step - loss: 0.4121 - accuracy: 0.7714 - val_loss: 0.0915 - val_accuracy: 0.9679\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9714 - val_loss: 0.0578 - val_accuracy: 0.9786\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9786 - val_loss: 0.0508 - val_accuracy: 0.9750\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9786 - val_loss: 0.0370 - val_accuracy: 0.9786\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9786 - val_loss: 0.0314 - val_accuracy: 0.9821\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9786 - val_loss: 0.0266 - val_accuracy: 0.9821\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9821 - val_loss: 0.0252 - val_accuracy: 0.9821\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9821 - val_loss: 0.0258 - val_accuracy: 0.9821\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9750 - val_loss: 0.0253 - val_accuracy: 0.9893\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9821 - val_loss: 0.0263 - val_accuracy: 0.9893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.3681 - accuracy: 0.8857 - val_loss: 0.1651 - val_accuracy: 0.9857\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9821 - val_loss: 0.0890 - val_accuracy: 0.9929\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9857 - val_loss: 0.0610 - val_accuracy: 0.9929\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9964 - val_loss: 0.0500 - val_accuracy: 0.9893\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9893 - val_loss: 0.0398 - val_accuracy: 0.9929\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9964 - val_loss: 0.0367 - val_accuracy: 0.9893\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9893 - val_loss: 0.0293 - val_accuracy: 0.9964\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9857 - val_loss: 0.0288 - val_accuracy: 0.9929\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 0.0242 - val_accuracy: 0.9964\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.9893 - val_loss: 0.0252 - val_accuracy: 0.9929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EonfUeU6mso2",
        "outputId": "837e2d21-326a-4048-ed86-73e8c2d4f151"
      },
      "source": [
        "akurasi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 0.9859154929577465,\n",
              " 0.971830985915493,\n",
              " 1.0,\n",
              " 0.9859154929577465,\n",
              " 0.9577464788732394,\n",
              " 0.9859154929577465,\n",
              " 0.9859154929577465,\n",
              " 1.0,\n",
              " 0.971830985915493]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up_9xSDXebET",
        "outputId": "c7f0131a-36e6-4b00-c614-a38067d24a08"
      },
      "source": [
        "presisi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9565217391304348,\n",
              " 0.975609756097561,\n",
              " 0.972972972972973,\n",
              " 1.0,\n",
              " 0.9761904761904762]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9vIl6LvhWQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d28872-6f06-49f6-8dc3-d48640c40bf0"
      },
      "source": [
        "recall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 0.975609756097561,\n",
              " 0.9459459459459459,\n",
              " 1.0,\n",
              " 0.9767441860465116,\n",
              " 0.9777777777777777,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9761904761904762]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFnOkyzgpqGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e165956-1aae-4f99-8bb6-2daebd079e91"
      },
      "source": [
        "print('Rata-rata akurasi untuk 10 kali pembelajaran: ' + str(np.mean(akurasi)))\n",
        "print('Rata-rata presisi untuk 10 kali pembelajaran: ' + str(np.mean(presisi)))\n",
        "print('Rata-rata recall untuk 10 kali pembelajaran: ' + str(np.mean(recall)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rata-rata akurasi untuk 10 kali pembelajaran: 0.9845070422535211\n",
            "Rata-rata presisi untuk 10 kali pembelajaran: 0.9881294944391446\n",
            "Rata-rata recall untuk 10 kali pembelajaran: 0.9852268142058274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWUnzS_KI_il"
      },
      "source": [
        "# **Cek Apakah Model Overfit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnH7Ilm_Ja30"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "def create_model(hidden_layers, learn_rate, neurons):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(14))\n",
        "  for i in range(hidden_layers):\n",
        "    model.add(Dense(neurons, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  optimizer = SGD(learning_rate=learn_rate)\n",
        "  model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs = 10, batch_size = 32, verbose=0)\n",
        "\n",
        "param_grid = {'hidden_layers': [1], 'learn_rate': [1], 'neurons': [2]}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10, scoring='accuracy',return_train_score=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4BXUBjcKIg9",
        "outputId": "c79932d8-ca8f-48e9-b24d-89900fa4e773"
      },
      "source": [
        "grid.fit(X_train,y_train)\n",
        "grid.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.87373905]),\n",
              " 'mean_score_time': array([0.13538685]),\n",
              " 'mean_test_score': array([0.98928571]),\n",
              " 'mean_train_score': array([0.99603175]),\n",
              " 'param_hidden_layers': masked_array(data=[1],\n",
              "              mask=[False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_learn_rate': masked_array(data=[1],\n",
              "              mask=[False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_neurons': masked_array(data=[2],\n",
              "              mask=[False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'hidden_layers': 1, 'learn_rate': 1, 'neurons': 2}],\n",
              " 'rank_test_score': array([1], dtype=int32),\n",
              " 'split0_test_score': array([1.]),\n",
              " 'split0_train_score': array([0.99603175]),\n",
              " 'split1_test_score': array([1.]),\n",
              " 'split1_train_score': array([0.99206349]),\n",
              " 'split2_test_score': array([1.]),\n",
              " 'split2_train_score': array([0.99603175]),\n",
              " 'split3_test_score': array([1.]),\n",
              " 'split3_train_score': array([0.99603175]),\n",
              " 'split4_test_score': array([1.]),\n",
              " 'split4_train_score': array([0.99603175]),\n",
              " 'split5_test_score': array([1.]),\n",
              " 'split5_train_score': array([0.99603175]),\n",
              " 'split6_test_score': array([0.96428571]),\n",
              " 'split6_train_score': array([0.99603175]),\n",
              " 'split7_test_score': array([0.96428571]),\n",
              " 'split7_train_score': array([1.]),\n",
              " 'split8_test_score': array([1.]),\n",
              " 'split8_train_score': array([0.99603175]),\n",
              " 'split9_test_score': array([0.96428571]),\n",
              " 'split9_train_score': array([0.99603175]),\n",
              " 'std_fit_time': array([0.11972584]),\n",
              " 'std_score_time': array([0.01538481]),\n",
              " 'std_test_score': array([0.01636634]),\n",
              " 'std_train_score': array([0.00177466])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiwP4eOiJ4rV",
        "outputId": "92139e83-683c-4f00-e151-38a65d01fd6d"
      },
      "source": [
        "scores = cross_val_score(grid, X_train, y_train, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f587f562950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f587ec537a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.99 (+/- 0.03)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}